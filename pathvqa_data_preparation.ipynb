{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3c2be95",
   "metadata": {},
   "source": [
    "### PathVQA Data Preparation\n",
    "\n",
    "This code will prepare the PathVQA data for evaluation. We need to evaluate PathVQA as following:\n",
    "\n",
    "Close-Ended: 50 \\\n",
    "Open-Ended: 550\n",
    "- What\n",
    "- Where\n",
    "- How\n",
    "- When\n",
    "- Why\n",
    "\n",
    "Since we want only the questions/answers displaying sensitive knowledge, we will only consider the data samples for which we have the length of both the answers and questions more than 5 words. If we are not able to find the respective number of samples, we can consider those data samples for which we have anwers or questions having more than 5 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5264d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617061a8",
   "metadata": {},
   "source": [
    "#### Defining the paths for PVQA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbb7394",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvqa_data_path = \"/data/mn27889/path-open-data/pathvqa-histopathology\"\n",
    "pvqa_images = os.path.join(pvqa_data_path, \"images\")\n",
    "pvqa_qas = os.path.join(pvqa_data_path, \"qas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610edab0",
   "metadata": {},
   "source": [
    "#### Considering images/qas from `train` subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8a0d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvqa_subset = \"train\"\n",
    "pvqa_images_subset_path = os.path.join(pvqa_images, pvqa_subset)\n",
    "pvqa_qas_subset_path = os.path.join(pvqa_qas, pvqa_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f448bb",
   "metadata": {},
   "source": [
    "#### Reading the QAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30022e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"train_qa.pkl\"\n",
    "qas_file_path = os.path.join(pvqa_qas_subset_path, file_name)\n",
    "with open(qas_file_path, 'rb') as file:\n",
    "    pvqa_qas_subset = pickle.load(file)\n",
    "\n",
    "print('Total Samples:',len(pvqa_qas_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e658a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvqa_qas_subset[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeba83ca",
   "metadata": {},
   "source": [
    "#### Differentiating the open-ended and close-ended questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvqa_qas_close_ended = [sample for sample in pvqa_qas_subset if sample['answer'].lower() == 'yes' or sample['answer'].lower() == 'no']\n",
    "len(pvqa_qas_close_ended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999956a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvqa_qas_open_ended = [sample for sample in pvqa_qas_subset if sample not in pvqa_qas_close_ended]\n",
    "len(pvqa_qas_open_ended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a783908",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(pvqa_qas_open_ended) + len(pvqa_qas_close_ended) == len(pvqa_qas_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804ffc3e",
   "metadata": {},
   "source": [
    "#### Finding the samples for which question and answer are equal to or more than 5 words.\n",
    "- For close-ended questions, only check question text since answer would be 'yes' or 'no'\n",
    "- For open-ended questions, check the both the question and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f958bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_close_ended_samples = [sample for sample in pvqa_qas_close_ended if len(sample['question'].split()) >= 5]\n",
    "len(valid_close_ended_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e0ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_open_ended_samples = [sample for sample in pvqa_qas_open_ended if len(sample['question'].split()) >= 5 and len(sample['answer'].split()) >= 5]\n",
    "len(valid_open_ended_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd13983",
   "metadata": {},
   "source": [
    "#### From open-ended questions, separating the questions starting with the following words:\n",
    "- What\n",
    "- Where\n",
    "- How\n",
    "- When\n",
    "- Why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb32aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_word = [sample['question'].split()[0].lower() for sample in valid_open_ended_samples]\n",
    "counts = Counter(first_word)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8e3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "what_question_samples = [sample for sample in valid_open_ended_samples if sample['question'].lower().startswith('what')]\n",
    "how_question_samples = [sample for sample in valid_open_ended_samples if sample['question'].lower().startswith('how')]\n",
    "why_question_samples = [sample for sample in valid_open_ended_samples if sample['question'].lower().startswith('why')]\n",
    "where_question_samples = [sample for sample in valid_open_ended_samples if sample['question'].lower().startswith('where')]\n",
    "when_question_samples = [sample for sample in valid_open_ended_samples if sample['question'].lower().startswith('when')]\n",
    "print('Total What Questions:', len(what_question_samples))\n",
    "print('Total How Questions:', len(how_question_samples))\n",
    "print('Total Why Questions:', len(why_question_samples))\n",
    "print('Total Where Questions:', len(where_question_samples))\n",
    "print('Total When Questions:', len(when_question_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06486dc8",
   "metadata": {},
   "source": [
    "### Compiling the data into a single dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb61bd67",
   "metadata": {},
   "source": [
    "Selecting the Top 50 samples of Close-Ended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3717f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvqa_eval_data_close_ended = pd.DataFrame(columns=['image_path', 'question', 'answer', 'question_type'])\n",
    "\n",
    "for sample in valid_close_ended_samples[0:50]:\n",
    "    image_path = os.path.join(pvqa_images_subset_path, sample['image'] + '.jpg')\n",
    "    question = sample['question']\n",
    "    answer = sample['answer']\n",
    "    question_type = 'close-ended'\n",
    "    pvqa_eval_data_close_ended.loc[len(pvqa_eval_data_close_ended)] = [image_path, question, answer, question_type]\n",
    "\n",
    "pvqa_eval_data_close_ended.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00962ae7",
   "metadata": {},
   "source": [
    "Selecting the Top 400 samples of What Open-Ended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da59a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvqa_eval_data_open_what = pd.DataFrame(columns=['image_path', 'question', 'answer', 'question_type'])\n",
    "\n",
    "for sample in what_question_samples[0:400]:\n",
    "    image_path = os.path.join(pvqa_images_subset_path, sample['image'] + '.jpg')\n",
    "    question = sample['question']\n",
    "    answer = sample['answer']\n",
    "    question_type = 'open-what'\n",
    "    pvqa_eval_data_open_what.loc[len(pvqa_eval_data_open_what)] = [image_path, question, answer, question_type]\n",
    "\n",
    "pvqa_eval_data_open_what.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fa03d8",
   "metadata": {},
   "source": [
    "Selecting all samples of How Open-Ended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039bff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvqa_eval_data_open_how = pd.DataFrame(columns=['image_path', 'question', 'answer', 'question_type'])\n",
    "\n",
    "for sample in how_question_samples:\n",
    "    image_path = os.path.join(pvqa_images_subset_path, sample['image'] + '.jpg')\n",
    "    question = sample['question']\n",
    "    answer = sample['answer']\n",
    "    question_type = 'open-how'\n",
    "    pvqa_eval_data_open_how.loc[len(pvqa_eval_data_open_how)] = [image_path, question, answer, question_type]\n",
    "\n",
    "pvqa_eval_data_open_how.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951c4e39",
   "metadata": {},
   "source": [
    "Selecting all samples of Why Open-Ended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252d6de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvqa_eval_data_open_why = pd.DataFrame(columns=['image_path', 'question', 'answer', 'question_type'])\n",
    "\n",
    "for sample in why_question_samples:\n",
    "    image_path = os.path.join(pvqa_images_subset_path, sample['image'] + '.jpg')\n",
    "    question = sample['question']\n",
    "    answer = sample['answer']\n",
    "    question_type = 'open-why'\n",
    "    pvqa_eval_data_open_why.loc[len(pvqa_eval_data_open_why)] = [image_path, question, answer, question_type]\n",
    "\n",
    "pvqa_eval_data_open_why.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9be8a0",
   "metadata": {},
   "source": [
    "Selecting all samples of Where Open-Ended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcea91fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvqa_eval_data_open_where = pd.DataFrame(columns=['image_path', 'question', 'answer', 'question_type'])\n",
    "\n",
    "for sample in where_question_samples:\n",
    "    image_path = os.path.join(pvqa_images_subset_path, sample['image'] + '.jpg')\n",
    "    question = sample['question']\n",
    "    answer = sample['answer']\n",
    "    question_type = 'open-where'\n",
    "    pvqa_eval_data_open_where.loc[len(pvqa_eval_data_open_where)] = [image_path, question, answer, question_type]\n",
    "\n",
    "pvqa_eval_data_open_where.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629346c7",
   "metadata": {},
   "source": [
    "Selecting all samples of When Open-Ended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dcad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvqa_eval_data_open_when = pd.DataFrame(columns=['image_path', 'question', 'answer', 'question_type'])\n",
    "\n",
    "for sample in when_question_samples:\n",
    "    image_path = os.path.join(pvqa_images_subset_path, sample['image'] + '.jpg')\n",
    "    question = sample['question']\n",
    "    answer = sample['answer']\n",
    "    question_type = 'open-when'\n",
    "    pvqa_eval_data_open_when.loc[len(pvqa_eval_data_open_when)] = [image_path, question, answer, question_type]\n",
    "\n",
    "pvqa_eval_data_open_when.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e64f7dc",
   "metadata": {},
   "source": [
    "### Uploading all the images to Google Drive and get the drive links\n",
    "\n",
    "Since we will be using the Google Form for the evaluation, we need to upload all the images to a specific Google Drive Folder. Then we need to get the drive link of each image and provide it to evaluators.\n",
    "\n",
    "1. Move all the PathVQA images from server into a specific folder\n",
    "2. Upload the Folder to google drive\n",
    "3. Prepare a Google App Script to get the name and links (URL) of those files from the google drive folder in a google sheet\n",
    "4. Map the names from Google Sheet and Dataframes to get the URLs of each image onto Google Drive\n",
    "5. The resulting dataframes will be the final csv files which will be provided to evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c47a4ca",
   "metadata": {},
   "source": [
    "Firstly moving all the images for all question types in a specific folder to be uploaded to Google Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0293ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_images_path_all = np.concatenate([pvqa_eval_data_close_ended['image_path'].unique(),\n",
    "                                        pvqa_eval_data_open_what['image_path'].unique(),\n",
    "                                        pvqa_eval_data_open_how['image_path'].unique(),\n",
    "                                        pvqa_eval_data_open_why['image_path'].unique(),\n",
    "                                        pvqa_eval_data_open_where['image_path'].unique(),\n",
    "                                        pvqa_eval_data_open_when['image_path'].unique()])\n",
    "unique_images_path_all = np.unique(unique_images_path_all)\n",
    "print('Total Unique Images for Evaluation:', len(unique_images_path_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0aa6f2",
   "metadata": {},
   "source": [
    "Moving all these images in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a57782",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvqa_eval_images_dir = 'PathVQA_Eval_Images'\n",
    "os.makedirs(pvqa_eval_images_dir, exist_ok=True)\n",
    "for image_path in unique_images_path_all:\n",
    "    shutil.copy(image_path, pvqa_eval_images_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b132361d",
   "metadata": {},
   "source": [
    "Now upload this folder onto the Google Driver. Then run the following scritpin Apps Script (script.google.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb0fbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function listFolderContents2() {\n",
    "#   var foldername = 'PathVQA_Eval_Images';\n",
    "#   var folderlisting = 'File Names and Links - '+ foldername;\n",
    "\n",
    "#   var folders = DriveApp.getFoldersByName(foldername);\n",
    "#   var folder = folders.next();\n",
    "#   var contents = folder.getFiles();\n",
    "\n",
    "#   var ss = SpreadsheetApp.create(folderlisting);\n",
    "#   var sheet = ss.getActiveSheet();\n",
    "#   sheet.appendRow(['name','link']);\n",
    "\n",
    "#   var file;\n",
    "#   var name;\n",
    "#   var link;\n",
    "#   var row;\n",
    "\n",
    "#   while(contents.hasNext()) {\n",
    "#     file = contents.next();\n",
    "#     name = file.getName();\n",
    "#     link = file.getUrl();\n",
    "#     sheet.appendRow([name,link]);\n",
    "#   }\n",
    "# };"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53daf6ba",
   "metadata": {},
   "source": [
    "After running the above script, a new excel file will be created with the names and Google Drive Links of the files. That excel sheet needs to be downloaded and mapped back to all the individual question sets to finalize the image URLs in the Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cd8a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eval_dir = 'data_eval'\n",
    "pathvqa_drive_links_file = os.path.join(data_eval_dir, \"file_names_and_links_PathVQA_Eval_Images.csv\")\n",
    "pathvqa_drive_links = pd.read_csv(pathvqa_drive_links_file)\n",
    "pathvqa_drive_links.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261dc7b9",
   "metadata": {},
   "source": [
    "Changing the name of each file to complete path for correct mapping later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93479561",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathvqa_drive_links['image_path'] = pathvqa_drive_links['name'].apply(lambda x: os.path.join(pvqa_images_subset_path, x))\n",
    "pathvqa_drive_links['image_id'] = pathvqa_drive_links['name'].apply(lambda x: x.split('.')[0])\n",
    "pathvqa_drive_links.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19584bb",
   "metadata": {},
   "source": [
    "### Mapping the Google Drive Links with each question set separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cddea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvqa_eval_data_close_ended = pd.merge(pvqa_eval_data_close_ended, pathvqa_drive_links, on='image_path', how='left')\n",
    "pvqa_eval_data_close_ended.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1351ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvqa_eval_data_open_what = pd.merge(pvqa_eval_data_open_what, pathvqa_drive_links, on='image_path', how='left')\n",
    "pvqa_eval_data_open_what.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4592e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvqa_eval_data_open_how = pd.merge(pvqa_eval_data_open_how, pathvqa_drive_links, on='image_path', how='left')\n",
    "pvqa_eval_data_open_how.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30943bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvqa_eval_data_open_where = pd.merge(pvqa_eval_data_open_where, pathvqa_drive_links, on='image_path', how='left')\n",
    "pvqa_eval_data_open_where.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e7ba71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvqa_eval_data_open_why = pd.merge(pvqa_eval_data_open_why, pathvqa_drive_links, on='image_path', how='left')\n",
    "pvqa_eval_data_open_why.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc01f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvqa_eval_data_open_when = pd.merge(pvqa_eval_data_open_when, pathvqa_drive_links, on='image_path', how='left')\n",
    "pvqa_eval_data_open_when.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325ad480",
   "metadata": {},
   "source": [
    "### Creating the final dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b00143",
   "metadata": {},
   "source": [
    "Joining all these datasets into one dataframe to extract the final dataset to be used for evaluation of PathVQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebecd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_data_pathvqa = pd.concat([pvqa_eval_data_close_ended.head(),\n",
    "                            pvqa_eval_data_open_what.head(),\n",
    "                            pvqa_eval_data_open_how.head(),\n",
    "                            pvqa_eval_data_open_why.head(),\n",
    "                            pvqa_eval_data_open_where.head(),\n",
    "                            pvqa_eval_data_open_when.head()]).reset_index(drop=True)\n",
    "\n",
    "vqa_data_pathvqa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dd229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_data_pathvqa[['image_id', 'link', 'question_type', 'question', 'answer']].to_csv('data_eval/pathvqa_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3433f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "path-opendata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
